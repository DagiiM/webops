{% extends 'base.html' %}
{% load static %}
{% block title %}Deploy LLM Model - {{ branding.site_name }}{% endblock %}
{% block header_title %}Deploy LLM Model{% endblock %}

{% block content %}
<div class="webops-page-header">
    <div>
        <h2 class="webops-page-title">Deploy LLM Model</h2>
        <p class="webops-text-muted">Deploy a Large Language Model using vLLM</p>
    </div>
    <a href="{% url 'deployments:llm_list' %}" class="webops-btn webops-btn-secondary">
        <span class="material-icons">arrow_back</span>
        Back to LLM Models
    </a>
</div>

<div class="webops-card">
    <div class="webops-card-header">
        <h3 class="webops-h3">Model Configuration</h3>
    </div>
    <div class="webops-card-body">
        <form method="POST" id="llmForm">
            {% csrf_token %}

            <div class="webops-form-group">
                <label for="name" class="webops-label webops-label-required">Deployment Name</label>
                <input type="text" id="name" name="name" class="webops-input" required
                       pattern="[a-z0-9-_]+"
                       placeholder="gpt2-deployment"
                       autocomplete="off">
                <small class="webops-input-help">Lowercase letters, numbers, hyphens, and underscores only</small>
            </div>

            <div class="webops-form-group">
                <label for="model_name" class="webops-label webops-label-required">Model Name</label>
                <input type="text" id="model_name" name="model_name" class="webops-input" required
                       placeholder="gpt2 or meta-llama/Llama-2-7b-hf"
                       autocomplete="off">
                <small class="webops-input-help">Hugging Face model ID (e.g., gpt2, meta-llama/Llama-2-7b-hf)</small>
            </div>

            <div class="webops-p-md webops-mb-lg" style="background: rgba(0, 255, 136, 0.1); border-radius: var(--webops-radius-md); border-left: 4px solid var(--webops-color-success);">
                <div class="webops-flex webops-gap-sm" style="align-items: flex-start;">
                    <span class="material-icons webops-text-success" style="font-size: 20px;">link</span>
                    <div class="webops-text-sm">
                        <strong class="webops-font-semibold">Need access to private models?</strong>
                        <p class="webops-text-secondary" style="margin: 4px 0 0 0;">
                            Connect your Hugging Face account in <a href="{% url 'integrations_dashboard' %}" class="webops-text-primary">Integrations</a> to deploy private models.
                        </p>
                    </div>
                </div>
            </div>

            <div class="webops-form-row">
                <div class="webops-form-group">
                    <label for="tensor_parallel_size" class="webops-label">Number of GPUs</label>
                    <input type="number" id="tensor_parallel_size" name="tensor_parallel_size"
                           class="webops-input" value="1" min="1" max="8">
                    <small class="webops-input-help">Tensor parallelism across GPUs (default: 1)</small>
                </div>

                <div class="webops-form-group">
                    <label for="gpu_memory_utilization" class="webops-label">GPU Memory</label>
                    <input type="number" id="gpu_memory_utilization" name="gpu_memory_utilization"
                           class="webops-input" value="0.9" min="0.1" max="1.0" step="0.1">
                    <small class="webops-input-help">Fraction of GPU memory to use (0.1-1.0)</small>
                </div>
            </div>

            <div class="webops-form-row">
                <div class="webops-form-group">
                    <label for="dtype" class="webops-label">Data Type</label>
                    <select id="dtype" name="dtype" class="webops-input">
                        <option value="auto">Auto</option>
                        <option value="float16">Float16 (Recommended)</option>
                        <option value="bfloat16">BFloat16</option>
                        <option value="float32">Float32</option>
                    </select>
                    <small class="webops-input-help">Model precision (float16 recommended for most models)</small>
                </div>

                <div class="webops-form-group">
                    <label for="quantization" class="webops-label">Quantization</label>
                    <select id="quantization" name="quantization" class="webops-input">
                        <option value="">None</option>
                        <option value="awq">AWQ</option>
                        <option value="gptq">GPTQ</option>
                        <option value="squeezellm">SqueezeLLM</option>
                    </select>
                    <small class="webops-input-help">Reduce memory usage (requires quantized model)</small>
                </div>
            </div>

            <div class="webops-form-group">
                <label for="max_model_len" class="webops-label">Max Context Length (Optional)</label>
                <input type="number" id="max_model_len" name="max_model_len"
                       class="webops-input" placeholder="e.g., 4096">
                <small class="webops-input-help">Override model's maximum context length (leave empty for auto)</small>
            </div>

            <div class="webops-p-md webops-mb-lg" style="background: rgba(0, 170, 255, 0.1); border-radius: var(--webops-radius-md); border-left: 4px solid var(--webops-color-info);">
                <div class="webops-flex webops-gap-sm" style="align-items: flex-start;">
                    <span class="material-icons webops-text-info" style="font-size: 20px;">info</span>
                    <div class="webops-text-sm">
                        <strong class="webops-font-semibold">Deployment Process</strong>
                        <p class="webops-text-secondary" style="margin: 4px 0 0 0;">
                            The deployment will download the model from Hugging Face, set up vLLM environment, and start the inference server.
                            This may take several minutes depending on model size. You can monitor progress in the deployment details page.
                        </p>
                        <p class="webops-text-secondary" style="margin: 8px 0 0 0;">
                            <strong>Note:</strong> vLLM requires GPU access. Ensure your system has available GPU resources.
                        </p>
                    </div>
                </div>
            </div>

            <div class="webops-flex webops-gap-sm">
                <button type="submit" class="webops-btn webops-btn-primary">
                    <span class="material-icons">smart_toy</span>
                    Deploy Model
                </button>
                <a href="{% url 'deployments:llm_list' %}" class="webops-btn webops-btn-secondary">Cancel</a>
            </div>
        </form>
    </div>
</div>

<!-- Enhanced Model Browser Card -->
<div class="webops-card webops-model-browser-card" id="webops-model-browser">
    <div class="webops-card-header">
        <div class="webops-flex webops-items-center webops-gap-2">
            <span class="material-icons webops-text-warning">hub</span>
            <h3 class="webops-h3 webops-m-0">Model Browser</h3>
        </div>
        <div class="webops-flex webops-items-center webops-gap-2">
            <span class="webops-text-xs webops-text-muted">Powered by Hugging Face</span>
        </div>
    </div>

    <div class="webops-card-body">
        <!-- Search and Filter Controls -->
        <div class="webops-model-browser-controls">
            <div class="webops-form-row">
                <div class="webops-form-group webops-flex-1">
                    <label for="webops-model-search" class="webops-label">Search Models</label>
                    <div class="webops-input-group">
                        <span class="material-icons webops-input-group-icon">search</span>
                        <input type="text" id="webops-model-search" class="webops-input"
                               placeholder="Search by name, author, or description..."
                               autocomplete="off">
                    </div>
                </div>

                <div class="webops-form-group">
                    <label for="webops-model-category" class="webops-label">Category</label>
                    <select id="webops-model-category" class="webops-input">
                        <option value="all">All Models</option>
                        <option value="testing">Testing & Small</option>
                        <option value="popular">Popular 7B</option>
                        <option value="deepseek">DeepSeek Models</option>
                        <option value="quantized">Quantized Models</option>
                    </select>
                </div>

                <div class="webops-form-group">
                    <label for="webops-model-sort" class="webops-label">Sort By</label>
                    <select id="webops-model-sort" class="webops-input">
                        <option value="trending">Trending</option>
                        <option value="downloads">Most Downloads</option>
                        <option value="likes">Most Likes</option>
                        <option value="name">Name</option>
                    </select>
                </div>
            </div>
        </div>

        <!-- Loading Indicator -->
        <div class="webops-model-browser-loading" id="webops-loading-indicator">
            <div class="webops-flex webops-flex-col webops-items-center webops-gap-3 webops-py-8">
                <div class="webops-spinner"></div>
                <p class="webops-text-sm webops-text-muted">Loading models...</p>
            </div>
        </div>

        <!-- Error Container -->
        <div class="webops-model-browser-error" id="webops-error-container"></div>

        <!-- Models Grid -->
        <div class="webops-models-grid" id="webops-models-grid">
            <!-- Models will be dynamically loaded here -->
        </div>

        <!-- Load More Button -->
        <div class="webops-model-browser-footer">
            <button class="webops-btn webops-btn-secondary webops-btn-sm" id="webops-load-more">
                <span class="material-icons">expand_more</span>
                Load More Models
            </button>
        </div>
    </div>
</div>

<!-- Compare Button -->
<button class="webops-btn webops-btn-primary webops-btn-sm" id="webops-compare-btn">
    <span class="material-icons">compare</span>
    Compare (0)
</button>

<!-- Model Comparison Panel -->
<div class="webops-compare-panel" id="webops-compare-panel">
    <!-- Panel content will be dynamically loaded here -->
</div>

<script src="{% static 'js/model-browser.js' %}"></script>
<link rel="stylesheet" href="{% static 'css/model-browser-enhancements.css' %}">

<!-- LLM Auto-Detection Preview -->
<script src="{% static 'js/llm-detection-preview.js' %}"></script>
<link rel="stylesheet" href="{% static 'css/llm-detection-preview.css' %}">

<script>
document.getElementById('llmForm').addEventListener('submit', function() {
    showLoader();
});
</script>
{% endblock %}
